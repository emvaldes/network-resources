#!/usr/bin/env bash

## File: scripts/parse-listings.shell

## Purpose: Parse a set of IP addresses against a directory of configuration files
##          and produce detailed per-IP reports in JSON and CSV format.
## Requirements: Bash v4+ and GNU utilities (jq, find, grep, sed, etc.)

## > nohup bash -x ./scripts/parse-listings.shell \
##     --verbose \
##     --debug \
##     --classify \
##     --logs \
##     --ips-list=ips.list \
##     --devices=devices.list \
##     --sites='cisco,fortinet,misc' \
##   > ./run.log 2>&1 &

set -euo pipefail  ## Strict mode: exit on error, undefined var use, and pipeline failure
# set -x;          ## Enable for execution tracing/debugging

## POSIX locale standard
export LC_ALL=C   ## Ensure consistent sorting and character handling (POSIX-compliant)

# Create a secure, temporary working directory (auto-cleaned at script exit)
export TMP_DIR="$( mktemp -d )";
trap '[[ -d "${TMP_DIR}" ]] && rm -rf "${TMP_DIR}"' EXIT;

#------------------------------------------------------------------------------#

# Load common utility functions (logging, platform detection, etc.)
source ./scripts/tools-devops.shell;
source ./scripts/tools-listings.shell;

#------------------------------------------------------------------------------#
## This function acts as the primary driver for the parsing pipeline. It:
##   - Processes CLI arguments and sets defaults
##   - Validates required input files
##   - Loads site/device/IP filters if provided
##   - Initializes environment variables and folders
##   - Performs outer batching of IPs and inner batching of configs
##   - For each IP/config pair, spawns background jobs to generate reports

function main () {
    ## tracking_process ${FUNCNAME} "${@}";
    oIFS="${IFS}";

    ## Process command-line arguments and map them to local variables
    for xitem in "${@}"; do
      IFS='=' read -r key value <<< "$(
        echo -e "${xitem}" | sed -e '1s|^\(-\)\{1,\}||'
      )"; #echo -e "\nxitem: '${xitem}'\nkey: '${key}'\t->\tvalue: '${value}'";

      #### ---------------------------------------------------------------------
      ## Match accepted arguments
      [[ $key =~ ^(classify|g)$ ]] && export classify_targets=true;
      [[ $key =~ ^(configs|c)$ ]] && export configs_dirpath="${value}";
      [[ $key =~ ^(devices|d)$ ]] && export target_devices="${value}";
      [[ $key =~ ^(file-ext|x)$ ]] && export file_extensions+=(
        $( print "${value}" | tr ':,;\n ' '\n' )
      );
      [[ $key =~ ^(interval|l)$ ]] && export delaying_factor="${value}";
      [[ $key =~ ^(ips-list|i)$ ]] && export target_addresses="${value}";
      [[ $key =~ ^(logs|o)$ ]] && export enable_logging=true;
      [[ $key =~ ^(jobs|j)$ ]] && export parallel_threads="${value}";
      [[ $key =~ ^(matrix|m)$ ]] && export matrix_filename="${value}";
      [[ $key =~ ^(reports|r)$ ]] && export reports_folder="${value}";
      [[ $key =~ ^(sites|s)$ ]] && export target_sites="${value}";
      [[ $key =~ ^(validate|v)$ ]] && export validate_address=true;

      #### ---------------------------------------------------------------------
      ## Special options
      [[ $key == "help" ]] && local script_helper=true;
      [[ $key == "debug" ]] && local debug=true;
      [[ $key == "dry-run" ]] && local dry_run=true;
      [[ $key == "verbose" ]] && local verbose=true;
    done; IFS="${oIFS}";

    #### -----------------------------------------------------------------------
    ## Set custom values if not supplied
    [[ -z ${delaying_factor:-} ]] && export delaying_factor="0.05";
    [[ -z ${target_addresses:-} ]] && export target_addresses="ips.list";
    [[ -z ${target_devices:-} ]] && export target_devices=false;
    [[ -z ${parallel_threads:-} ]] && export parallel_threads=100;
    [[ -z ${target_sites:-} ]] && export target_sites=false;

    #### -----------------------------------------------------------------------
    ## Set default values if not supplied
    [[ -z ${script_helper:-} ]] && script_helper=false;
    [[ -z ${debug:-} ]] && debug=false;
    [[ -z ${dry_run:-} ]] && dry_run=false;
    [[ -z ${verbose:-} ]] && verbose=false;

    #### -----------------------------------------------------------------------
    ## Display usage help if requested
    if [[ ${script_helper:-} == true ]]; then
      display_help "${script_name}" "listings";
      exit 0;
    fi;

    local start_time="$(date '+%Y-%m-%d %H:%M:%S')"
    SECONDS=0;  ## Start timer

    #### -----------------------------------------------------------------------
    ## Enabling IP/CIDR Blocks Group Classification
    [[ -z ${classify_targets:-} ]] && local classify_targets=false;

    ## Generate master list of config files only once
    ## Custom/Default configs folder:
    export configs_dirpath="${configs_dirpath:-configs}";

    #### -----------------------------------------------------------------------
    ## Target Configurations (file-extensions):
    ## Set default file extensions if none provided
    if [[ -z ${file_extensions+x} || ${#file_extensions[@]} -eq 0 ]]; then
      file_extensions=( cfg conf cnf );
    fi;

    #### -----------------------------------------------------------------------
    ## Processing Target Devices Listing (default: devices.list or inline string)
    declare -a target_devices_source=();
    if [[ -n "${target_devices:-}" && -f "${target_devices}" ]]; then
            mapfile -t target_devices_source < <(
              grep -v '^\s*$' "${target_devices}" | tr -d '\r'
            );
      elif [[ "${target_devices}" =~ ^[0-9] ]]; then
            mapfile -t target_devices_source < <(
              print "${target_devices}" | tr ', ' '\n' | grep -v '^\s*$'
            );
      else  message "Project Target Devices-Listing file not found: ${target_devices}";
    fi;

    #### -----------------------------------------------------------------------
    ## Processing Custom/Default the Translation-Matrix (source):
    ## Load and validate translation matrix (used for grouping logic)
    [[ -z "${matrix_filename:-}" ]] && export matrix_filename="matrix.json";
    if [[ ! -f "${matrix_filename}" ]]; then
            error_message "Project Source Matrix-Configs file not found: ${matrix_filename}";
            return 1;
      elif  ! jq -e 'length > 0' "${matrix_filename}" &>/dev/null; then
            error_message "Matrix file is missing, invalid, or empty: ${matrix_filename}";
            return 2;
      else  export matrix_configs="$(
              cat "${matrix_filename}"
            )";
    fi;

    #### -----------------------------------------------------------------------
    ## Custom/Default reports folder:
    export reports_folder="${reports_folder:-reports}";
    mkdir -p "${reports_folder}";

    export output_csv="${reports_folder}/reports.csv";

    #### -----------------------------------------------------------------------
    ## Validating IP Addresses (Skipping?)
    [[ -z ${validate_address:-} ]] && export validate_address=false;

    #### -----------------------------------------------------------------------
    if [[ "${verbose}" == true ]]; then
      {
        message "[INFO] Date: ${start_time}";
        newline;
        message "[INFO] Script: ${script_name}";
        message "[INFO] PID: $$";
        newline;
        message "[INFO] User: $( whoami )";
        message "[INFO] Host: $( hostname )";
        message "[INFO] OS: ${OSTYPE}";
        message "[INFO] Shell: ${BASH_VERSION}";
        newline;
        message "[INFO] Logging Output Directory: ${logs_location}";
        message "[INFO] Temp Directory: ${TMP_DIR}";
        newline;
        message "[INFO] Classify Targets: ${classify_targets}";
        message "[INFO] Configurations Path: ${configs_dirpath}";
        message "[INFO] Filtering Devices: ${target_devices}";
        message "[INFO] File Extensions: ${file_extensions}";
        message "[INFO] Delaying Factor: ${delaying_factor}";
        message "[INFO] Target Addresses: ${target_addresses}";
        message "[INFO] Enable Logging: ${enable_logging}";
        message "[INFO] Parallelism Factor: ${parallel_threads}";
        message "[INFO] Matrix Filename: ${matrix_filename}";
        message "[INFO] Reports Folder: ${reports_folder}";
        message "[INFO] Target Locations: ${target_sites}";
        message "[INFO] Validate Address: ${validate_address}";
        message "[INFO] Debug: ${debug}";
        message "[INFO] Dry-Run: ${dry_run}";
        message "[INFO] Verbose: ${verbose}";
        newline;
      } >> "${actions_logsfile}";
    fi;

    #### -----------------------------------------------------------------------
    if [[ "${verbose}" == true ]]; then
      {
        message "Target (${target_devices}) (count): ${#target_devices_source[@]}";
        newline;
        for device in "${target_devices_source[@]}"; do
          message "  - ${device}";
        done; newline;
      } >> "${actions_logsfile}";
    fi;

    #### -----------------------------------------------------------------------
    ## Cache list of configuration files to avoid repeated find calls
    local configs_list_cache="${cache_location}/configs.list";

    if [[ ! -f "${configs_list_cache}" ]]; then
            local -a find_cmd=(
              find "${configs_dirpath}" -type f \(
            );
            for ext in "${file_extensions[@]}"; do
              find_cmd+=( -iname "*.${ext}" -o );
            done;
            unset 'find_cmd[-1]';  ## Remove trailing -o
            find_cmd+=( \) );
            declare -a discovered_files=();
            while IFS= read -r fullpath; do
              filename="$(
                basename "${fullpath}"
              )";
              device_name="${filename%.*}"  ## strip extension like .cfg
              ## Apply --devices filter if present
              if [[ "${#target_devices_source[@]}" -gt 0 ]]; then
                matched=false;
                for pattern in "${target_devices_source[@]}"; do
                  if [[ "${device_name}" =~ ${pattern} ]]; then
                    matched=true;
                    break;
                  fi;
                done;
                [[ "${matched}" == false ]] && \
                   continue  # skip if no match;
              fi;
              discovered_files+=( "${fullpath}" );
            done < <( "${find_cmd[@]}" | sort );
            printf '%s\n' "${discovered_files[@]}" > "${configs_list_cache}";
            [[ "${verbose}" == true ]] && \
              message "Generated configs.list at ${configs_list_cache}";
      else  [[ "${verbose}" == true ]] && \
            message "Using cached configs.list from ${configs_list_cache}";
    fi;
    # print_file "${configs_list_cache}";

    #### -----------------------------------------------------------------------
    ## Optional --sites filter: limit to specific site directories only
    if [[ -n "${target_sites:-}" && "${target_sites}" != "false" ]]; then

        #### -------------------------------------------------------------------
        oIFS="${IFS}"; IFS=',';
        read -r -a site_filters <<< "${target_sites}";
        # for site in ${site_filters[@]}; do message "Site: ${site}"; done;
        IFS="${oIFS}";
        declare -a filtered_configs=();
        while IFS= read -r path; do
          # message "Target Path: [${path}]";
          site_folder="$(
            sed -E "s|^${configs_dirpath}/||" <<< "${path}" | \
            sed -E 's|/.*||'
          )";
          # message "Site Folder: ${site_folder}";
          for site in "${site_filters[@]}"; do
            # message "Target Site: ${site}"
            if [[ "${site_folder}" == "${site}" ]]; then
              # message "Match Path: ${path}";
              filtered_configs+=( "${path}" );
              break;
            fi;
          done;
        done < "${configs_list_cache}";

        #### -------------------------------------------------------------------
        if [[ "${verbose}" == true ]]; then
          {
            message "Filtered Configurations (count): ${#filtered_configs[@]}";
            newline;
            for config in "${filtered_configs[@]}"; do
              message "  - $( relative_configpath ${config} )";
            done; newline;
          } >> "${actions_logsfile}";
        fi;

        #### -------------------------------------------------------------------
        ## Overwrite the cached configs list with only the filtered entries
        ## This ensures that downstream processing only sees site-matching files
        if [[ "${#filtered_configs[@]}" -eq 0 ]]; then
                message "[FILTER] No matching config files found for --sites=${target_sites}";
                : > "${configs_list_cache}";  ## Empty the file
                newline;
                exit 1;
          else  printf '%s\n' "${filtered_configs[@]}" > "${configs_list_cache}";
                # if [[ "${verbose}" == true ]]; then
                #   {
                #     message "[FILTER] Filtered configs.list at ${configs_list_cache}";
                #     message "[FILTER] Filtered configs.list contains: $(
                #       wc -l < "${configs_list_cache}" | awk '{print $1}'
                #     ) entries";
                #   } >> "${actions_logsfile}";
                # fi;
        fi;

    fi;

    #### -----------------------------------------------------------------------
    ## Processing Target Addresses Listing (default: ips.list or inline string)
    declare -a target_addresses_source=();
    if [[ -f "${target_addresses}" ]]; then
            mapfile -t target_addresses_source < <(
              grep -v '^\s*$' "${target_addresses}" | \
              tr -d '\r' | \
              sort -t . -k1,1n -k2,2n -k3,3n -k4,4n -u
            );
      elif [[ "${target_addresses}" =~ ^[0-9] ]]; then
            mapfile -t target_addresses_source < <(
              print "${target_addresses}" | \
              tr ', ' '\n' | \
              grep -v '^\s*$' | \
              sort -t . -k1,1n -k2,2n -k3,3n -k4,4n -u
            );
      else  error_message "Project Target IP-listing file not found: ${target_addresses}";
    fi;

    #### -----------------------------------------------------------------------
    if [[ "${verbose}" == true ]]; then
      {
        message "Loaded (default) IPs addresses (count): ${#target_addresses_source[@]}";
        newline;
        for ip in "${target_addresses_source[@]}"; do
          message "  - ${ip}";
        done; newline;
      } >> "${actions_logsfile}";
    fi;

    #### -----------------------------------------------------------------------
    ## Normalize and validate each IP using validate_address()
    declare -a target_listing=();
    for raw_ip in "${target_addresses_source[@]}"; do
      target_address="${raw_ip}";
      if validate_address; then
        target_listing+=( "${target_address}" );
      fi;
    done;

#### Starting: Batch-Processing - Superset Loop --------------------------- ####

    #### -----------------------------------------------------------------------
    ## Superset batching loop: Divide IPs into manageable chunks
    ip_batch_size=10;  ## Adjust as needed for system capacity
    total_ips="${#target_addresses_source[@]}";
    for (( ip_offset=0; ip_offset<total_ips; ip_offset+=ip_batch_size )); do
      target_listing=(
        "${target_addresses_source[@]:ip_offset:ip_batch_size}"
      ); export target_listing;

      {
        message "Processing IPs [${total_ips}]: ${ip_offset} -> $((
          ip_offset + ip_batch_size - 1
        ))";
        newline;
      } >> "${actions_logsfile}";

#### Starting: Batch-Processing - Outer Loop ------------------------------ ####

      #### ---------------------------------------------------------------------
      ## Begin placeholder-only batch structure (no processing)
      mapfile -t site_folders < <(
        cut -d/ -f2 ${cache_location}/configs.list | sort -u
      );
      local batch_size=5;

      #### ---------------------------------------------------------------------
      if [[ "${verbose}" == true ]]; then
        {
          message "Site Folders:";
          newline;
          for site in "${site_folders[@]}"; do
            message "  - ${site}";
          done;
          newline;
          message "Batch processing (outer):";
          message "Batch size: ${batch_size}";
          newline;
          message "Parallel threads:   ${parallel_threads}";
          message "Target IPs (count): ${#target_listing[@]}";
          newline;
        } >> "${actions_logsfile}";
      fi;

      ## Outter Batching (For-loop)
      for site in "${site_folders[@]}"; do

        #### -------------------------------------------------------------------
        oIFS="${IFS}"; IFS=$'\n';
        read -r -d '' -a site_files < <(
          grep -F "/${site}/" "${configs_list_cache}" && printf '\0'
        );
        IFS="${oIFS}";
        total_files=${#site_files[@]};

        #### -------------------------------------------------------------------
        if [[ "${verbose}" == true ]]; then
          {
            message "Target Site:   ${site}";
            message "Total Configs: ${total_files}";
            newline;
          } >> "${actions_logsfile}";
          # for site in "${site_files[@]}"; do message "Site: ${site}"; done;
        fi;

        #### -------------------------------------------------------------------
        ## Delete only top-level JSON files in ${targets_location} (preserve subfolders)
        if [[ -d ${targets_location} ]]; then
          find ${targets_location} -maxdepth 1 -type f -name '*.json' -delete 2>/dev/null;
          ## Confirm deletion was successful
          if compgen -G "${targets_location}/*.json" >/dev/null; then
            error_message "[FATAL] Failed to delete JSON files in ${targets_location} directory.";
            exit 2;
          fi;
        fi;

        #### -------------------------------------------------------------------
        ## Delete ${logs_location}/jobs directory and wait until fully removed
        rm -rf ${logs_location}/jobs;
        while [[ -d ${logs_location}/jobs ]]; do sleep 0.1; done;
        ## Confirm ${logs_location}/jobs is fully removed
        if [[ -d ${logs_location}/jobs ]]; then
          error_message "[FATAL] Failed to delete ${logs_location}/jobs directory.";
          exit 3;
        fi;

#### Starting: Batch-Processing - Inner Loop ------------------------------ ####

        ## Inner Batching (While-loop)
        offset=0;
        while [[ "${offset}" -lt "${total_files}" ]]; do
          export batch_id="$(
            printf '%s-%s' "$( date +%s%N )" "${RANDOM}" | \
            base64 | \
            tr -dc 'a-zA-Z0-9' | \
            cut -c1-12
          )";

          #### -----------------------------------------------------------------
          batch_slice=( "${site_files[@]:offset:batch_size}" );
          batch_suffix="$( date +%s )-${RANDOM}";
          batch_configs_list="configs--${batch_id}-${batch_suffix}.list";
          BATCH_CONFIGS="${TMP_DIR}/${batch_configs_list}";
          export BATCH_CONFIGS;
          touch "${BATCH_CONFIGS}";
          printf '%s\n' "${batch_slice[@]}" > "${BATCH_CONFIGS}";
          range_first=$(( offset+1 ));
          range_last=$(( offset + ${#batch_slice[@]} ));

          #### -----------------------------------------------------------------
          if [[ "${verbose}" == true ]]; then
            {
              message "Batch processing (inner):";
              message "Batch ID: ${batch_id}";
              newline;
              message "Batch offset:   ${offset}";
              message "Batch Suffix:   ${batch_suffix}";
              message "Batch FileName: ${batch_configs_list}";
              message "Batch Configs:  ${BATCH_CONFIGS}";
              list_file "${BATCH_CONFIGS}";
              newline;
              message "Batch Size:     ${#batch_slice[@]}";
              message "Batch Ranges:   ${range_first} -> ${range_last}";
              newline;
              for config in "${batch_slice[@]}"; do
                message "  - $(relative_configpath "${config}")";
              done;
              newline;
            } >> "${actions_logsfile}";
          fi;

          #### -----------------------------------------------------------------
          ## Advanced Background Jobs management workflow
          matching_configs ${BATCH_CONFIGS};
          :> "${targets_logsfile}";

          #### -----------------------------------------------------------------
          ## Compute and log unmapped IPs directly from difference
          declare -a discarded_ips=();
          for ip in "${target_addresses_source[@]}"; do
            found=false;
            for current in "${target_listing[@]}"; do
              if [[ "${ip}" == "${current}" ]]; then
                found=true;
                break;
              fi;
            done;
            [[ "${found}" == false ]] && discarded_ips+=( "${ip}" );
          done;

          #### -----------------------------------------------------------------
          if [[ "${verbose}" == true ]]; then
            if [[ "${#discarded_ips[@]}" -gt 0 ]]; then
              {
                message "Unmapped IPs (count): ${#discarded_ips[@]}";
                newline;
                for ip in "${discarded_ips[@]}"; do
                  message "  - ${ip}";
                done;
                newline;
              } >> "${actions_logsfile}";
            fi;
          fi;

          #### -----------------------------------------------------------------
          ## Launch and monitor parallel config parsing jobs for matched IPs
          manage_configs;

          offset=$(( offset + batch_size ));

        done;

#### Completed: Batch-Processing - Inner Loop ----------------------------- ####

        ## Exporting ./reports/reports.json data-sets into CSV output
        generate_csvoutput;

        #### -------------------------------------------------------------------
        ## Final consolidation step:
        ## Merge all per-site JSON files from ./targets/<ip>/<ip>--<site>.json
        ## into a single unified output at .cache/targets/<ip>.json.
        ## This runs only after all parsing and processing is complete.
        ## The intermediate ./targets/*.json files are already deleted after use.

        shopt -s nullglob;
        for ip_dir in "${targets_location}"/*/; do
          ip="$(
            basename "${ip_dir}"
          )";
          final_file="${cache_location}/targets/${ip}.json";
          mkdir -p "${cache_location}/targets";
          site_jsons=(
            "${ip_dir}/${ip}"--*.json
          );
          [[ "${#site_jsons[@]}" -eq 0 ]] && continue;
          if [[ -f "${final_file}" ]]; then
                jq -s '{
                  configs: (
                    map(.configs) | add |
                    unique_by( .config.site + ":" + .config.device )
                  )
                }' "${final_file}" "${site_jsons[@]}" > "${final_file}.tmp" && \
                mv -f "${final_file}.tmp" "${final_file}";
          else  jq -s '{
                  configs: (
                    map(.configs) | add |
                    unique_by(.config.site + ":" + .config.device)
                  )
                }' "${site_jsons[@]}" > "${final_file}";
          fi;
        done;
        shopt -u nullglob;

        #### -------------------------------------------------------------------
        ## Final cleanup: remove any remaining per-site JSON files and empty folders
        if [[ -d ${targets_location} ]]; then
          find "${targets_location}" -type f -name "*.json" -delete 2>/dev/null;
          find "${targets_location}" -type d -empty -delete 2>/dev/null;
        fi;

      done;

#### Completed:  Batch-Processing - Outer Loop ---------------------------- ####

    done;

#### Completed: Batch-Processing - Superset Loop -------------------------- ####

    #### -----------------------------------------------------------------------
    ## Post-processing: Normalize ./cache/targets/<ip>.json to grouped by site
    if [[ "${verbose}" == true ]]; then
      grouped_targets="${cache_location}/targets";
      {
        message "Post-processing: Normalizing JSON files";
        message "---------------------------------------";
        message "Grouped by site: ${grouped_targets}";
        newline;
        for fpath in "${grouped_targets}/"*.json; do
          # ip="$(basename "${fpath}" .json)";
          ip="$( basename "${fpath}" )";
          message "  - ${ip}";
        done;
        newline;
      } >> "${actions_logsfile}";
    fi;

    shopt -s nullglob;
    for target_file in "${cache_location}/targets/"*.json; do
      if [[ -s "${target_file}" ]]; then
        grouped_objects="$(
          jq '
            .configs
            | group_by(.config.site)
            | map({
                (.[0].config.site): map({
                  device: .config.device,
                  lines: .lines,
                  count: .count
                })
              })
            | add
          ' "${target_file}"
        )";
        jq . <<< "${grouped_objects}" > "${target_file}";
      fi;
    done;
    shopt -u nullglob;

    #### -----------------------------------------------------------------------
    if [[ "${verbose}" == true && -s "${output_csv}" ]]; then
      {
        message "CSV Report Summary (tabulated):";
        message "-------------------------------";
        print_file "${output_csv}" | cat -n;
        newline;
      } >> "${actions_logsfile}";
    fi;

    #### -----------------------------------------------------------------------
    ## Delete ${logs_location}/jobs directory and wait until fully removed
    rm -rf ${logs_location}/jobs; while [[ -d ${logs_location}/jobs ]]; do sleep 0.1; done;
    ## Confirm ${logs_location}/jobs is fully removed
    if [[ -d ${logs_location}/jobs ]]; then
      error_message "[FATAL] Failed to delete ${logs_location}/jobs directory.";
      exit 4;
    fi;

    #### -----------------------------------------------------------------------
    local elapsed="${SECONDS}";
    {
      message "Session Summary:";
      message "-------------------------------";
      message "Started at: ${start_time}";
      printf  "[INFO] Total runtime: %02d:%02d:%02d\n" \
              $(( elapsed / 3600 )) \
              $(( ( elapsed % 3600 ) / 60 )) \
              $(( elapsed % 60 ));
      newline;
    } >> "${actions_logsfile}";

    return 0;
}; alias parse-listings='main';

#------------------------------------------------------------------------------#

:> ${actions_logsfile};

rm -rf ${cache_location};
mkdir -p ${cache_location}/{jobs,targets};

rm -rf ${logs_location} 2>/dev/null;
mkdir -p ${logs_location}/{errors,jobs};

rm -rf ${targets_location} 2>/dev/null;
mkdir -p ${targets_location};

[[ -z "${script_name+x}" ]] && export script_name="${0}";

#------------------------------------------------------------------------------#

if [[ ${#@} -ge 1 && "${1,,}" =~ ^-*(h|help)$ ]]; then
        main --help ;
  else  main "${@}";
        ## newline; message "Done."; newline;
fi;

#------------------------------------------------------------------------------#
